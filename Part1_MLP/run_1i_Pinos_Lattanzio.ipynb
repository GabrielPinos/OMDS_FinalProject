{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86ef8b0b",
   "metadata": {},
   "source": [
    "# **FINAL PROJECT _ Optimization Methods for Data Science** \n",
    "### A.A. 2024-2025\n",
    "\n",
    "**Pinos Gabriel** - 1965035  \n",
    "**Federico Lattanzio** - 1886519\n",
    "\n",
    "pinos.1965035@studenti.uniroma1.it  \n",
    "lattanzio.1886519@studenti.uniroma1.it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c500a542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import requird packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n",
    "from warnings import filterwarnings\n",
    "import matplotlib.pyplot as plt\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a87f53d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import custom MLP functions\n",
    "from Functions_ij_Pinos_Lattanzio import train_model, cross_validate_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6f0d8d",
   "metadata": {},
   "source": [
    "## **Dataset overview**\n",
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695bd8b3",
   "metadata": {},
   "source": [
    "The project leverages a set of UTKFace-derived datasets, each composed of:\n",
    "\n",
    "- ResNet-extracted features labeled as feat_i\n",
    "\n",
    "- A ground-truth target column named `gt`, representing:\n",
    "\n",
    "  -  `AGE_PREDICTION.csv`: float age values ∈ [0, 100]\n",
    "\n",
    "  - `GENDER_CLASSIFICATION.csv`: binary labels (0 = Female, 1 = Male)\n",
    "\n",
    "  - `ETHNICITY_CLASSIFICATION.csv`: 5 ethnicity classes (0–4)\n",
    "\n",
    "We begin with the age prediction dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba24d312",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_df = pd.read_csv(\"../dataset/AGE_PREDICTION.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75487041",
   "metadata": {},
   "source": [
    "### **Preview ad structure of the `AGE_PREDICTION.csv` dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "843681f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 entries in AGE_PREDICTION dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_4</th>\n",
       "      <th>feat_5</th>\n",
       "      <th>feat_6</th>\n",
       "      <th>feat_7</th>\n",
       "      <th>feat_8</th>\n",
       "      <th>feat_9</th>\n",
       "      <th>feat_10</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_24</th>\n",
       "      <th>feat_25</th>\n",
       "      <th>feat_26</th>\n",
       "      <th>feat_27</th>\n",
       "      <th>feat_28</th>\n",
       "      <th>feat_29</th>\n",
       "      <th>feat_30</th>\n",
       "      <th>feat_31</th>\n",
       "      <th>feat_32</th>\n",
       "      <th>gt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.686191</td>\n",
       "      <td>-0.989465</td>\n",
       "      <td>-0.920503</td>\n",
       "      <td>1.607427</td>\n",
       "      <td>-0.896248</td>\n",
       "      <td>1.118974</td>\n",
       "      <td>-0.969456</td>\n",
       "      <td>1.811707</td>\n",
       "      <td>2.560955</td>\n",
       "      <td>3.803463</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.862891</td>\n",
       "      <td>-0.909545</td>\n",
       "      <td>-0.915361</td>\n",
       "      <td>-0.952061</td>\n",
       "      <td>-0.989461</td>\n",
       "      <td>1.911855</td>\n",
       "      <td>1.409705</td>\n",
       "      <td>2.303997</td>\n",
       "      <td>-0.981840</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.887917</td>\n",
       "      <td>4.915272</td>\n",
       "      <td>-0.939446</td>\n",
       "      <td>-0.343677</td>\n",
       "      <td>-0.964685</td>\n",
       "      <td>-0.478649</td>\n",
       "      <td>4.342395</td>\n",
       "      <td>-0.332870</td>\n",
       "      <td>-0.768041</td>\n",
       "      <td>-0.815375</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.939201</td>\n",
       "      <td>-0.965917</td>\n",
       "      <td>-0.969461</td>\n",
       "      <td>-0.934799</td>\n",
       "      <td>5.304822</td>\n",
       "      <td>0.934790</td>\n",
       "      <td>-0.410701</td>\n",
       "      <td>0.284690</td>\n",
       "      <td>4.919212</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.923215</td>\n",
       "      <td>2.746968</td>\n",
       "      <td>-0.918085</td>\n",
       "      <td>0.047804</td>\n",
       "      <td>-0.908587</td>\n",
       "      <td>-0.451752</td>\n",
       "      <td>2.984481</td>\n",
       "      <td>0.535007</td>\n",
       "      <td>-0.591029</td>\n",
       "      <td>-0.324043</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.809726</td>\n",
       "      <td>-0.929934</td>\n",
       "      <td>-0.891814</td>\n",
       "      <td>-0.881796</td>\n",
       "      <td>3.415373</td>\n",
       "      <td>1.044108</td>\n",
       "      <td>-0.442615</td>\n",
       "      <td>0.033648</td>\n",
       "      <td>2.628199</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.268866</td>\n",
       "      <td>-0.408416</td>\n",
       "      <td>-0.935145</td>\n",
       "      <td>0.731800</td>\n",
       "      <td>-0.922438</td>\n",
       "      <td>0.221781</td>\n",
       "      <td>-0.046606</td>\n",
       "      <td>1.149634</td>\n",
       "      <td>0.592136</td>\n",
       "      <td>1.357959</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.834968</td>\n",
       "      <td>-0.937475</td>\n",
       "      <td>-0.917737</td>\n",
       "      <td>-0.929519</td>\n",
       "      <td>-0.226282</td>\n",
       "      <td>1.608048</td>\n",
       "      <td>0.276169</td>\n",
       "      <td>1.246468</td>\n",
       "      <td>-0.363367</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.529231</td>\n",
       "      <td>-0.829957</td>\n",
       "      <td>-0.897425</td>\n",
       "      <td>0.921280</td>\n",
       "      <td>-0.865304</td>\n",
       "      <td>0.331018</td>\n",
       "      <td>-0.644940</td>\n",
       "      <td>1.296097</td>\n",
       "      <td>1.166863</td>\n",
       "      <td>2.036034</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.775411</td>\n",
       "      <td>-0.881967</td>\n",
       "      <td>-0.864018</td>\n",
       "      <td>-0.908001</td>\n",
       "      <td>-0.784495</td>\n",
       "      <td>1.329586</td>\n",
       "      <td>0.547925</td>\n",
       "      <td>1.195395</td>\n",
       "      <td>-0.810089</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.793087</td>\n",
       "      <td>1.832985</td>\n",
       "      <td>-0.964968</td>\n",
       "      <td>0.274521</td>\n",
       "      <td>-0.962229</td>\n",
       "      <td>-0.288595</td>\n",
       "      <td>2.333454</td>\n",
       "      <td>0.788157</td>\n",
       "      <td>-0.311396</td>\n",
       "      <td>0.353214</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.923235</td>\n",
       "      <td>-0.969646</td>\n",
       "      <td>-0.970492</td>\n",
       "      <td>-0.961975</td>\n",
       "      <td>2.462071</td>\n",
       "      <td>1.539259</td>\n",
       "      <td>-0.132857</td>\n",
       "      <td>0.922628</td>\n",
       "      <td>2.249941</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.627914</td>\n",
       "      <td>0.537031</td>\n",
       "      <td>-0.846287</td>\n",
       "      <td>0.484149</td>\n",
       "      <td>-0.802970</td>\n",
       "      <td>-0.255616</td>\n",
       "      <td>1.103370</td>\n",
       "      <td>0.905729</td>\n",
       "      <td>0.121083</td>\n",
       "      <td>0.820827</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.712115</td>\n",
       "      <td>-0.826480</td>\n",
       "      <td>-0.794454</td>\n",
       "      <td>-0.831328</td>\n",
       "      <td>1.042797</td>\n",
       "      <td>0.713609</td>\n",
       "      <td>-0.003151</td>\n",
       "      <td>0.097357</td>\n",
       "      <td>0.469993</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.825429</td>\n",
       "      <td>3.686025</td>\n",
       "      <td>-0.979020</td>\n",
       "      <td>0.053158</td>\n",
       "      <td>-0.983342</td>\n",
       "      <td>-0.448615</td>\n",
       "      <td>3.839871</td>\n",
       "      <td>0.161758</td>\n",
       "      <td>-0.641629</td>\n",
       "      <td>-0.414449</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.970626</td>\n",
       "      <td>-0.987172</td>\n",
       "      <td>-0.992049</td>\n",
       "      <td>-0.977634</td>\n",
       "      <td>4.310089</td>\n",
       "      <td>1.683480</td>\n",
       "      <td>-0.217012</td>\n",
       "      <td>1.010501</td>\n",
       "      <td>4.100075</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.978345</td>\n",
       "      <td>-0.941560</td>\n",
       "      <td>-0.906123</td>\n",
       "      <td>1.604776</td>\n",
       "      <td>-0.881297</td>\n",
       "      <td>0.819134</td>\n",
       "      <td>-0.879738</td>\n",
       "      <td>1.500830</td>\n",
       "      <td>1.694242</td>\n",
       "      <td>3.005683</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.845833</td>\n",
       "      <td>-0.906470</td>\n",
       "      <td>-0.917842</td>\n",
       "      <td>-0.910915</td>\n",
       "      <td>-0.926480</td>\n",
       "      <td>1.689097</td>\n",
       "      <td>1.170266</td>\n",
       "      <td>1.745933</td>\n",
       "      <td>-0.939529</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6.975595</td>\n",
       "      <td>-0.999944</td>\n",
       "      <td>-0.979416</td>\n",
       "      <td>5.483491</td>\n",
       "      <td>-0.976307</td>\n",
       "      <td>3.397312</td>\n",
       "      <td>-0.999714</td>\n",
       "      <td>2.934085</td>\n",
       "      <td>6.361970</td>\n",
       "      <td>9.293163</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.980985</td>\n",
       "      <td>-0.976980</td>\n",
       "      <td>-0.982636</td>\n",
       "      <td>-0.989800</td>\n",
       "      <td>-0.999934</td>\n",
       "      <td>5.141039</td>\n",
       "      <td>4.198592</td>\n",
       "      <td>6.156951</td>\n",
       "      <td>-0.999915</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     feat_1    feat_2    feat_3    feat_4    feat_5    feat_6    feat_7  \\\n",
       "0  2.686191 -0.989465 -0.920503  1.607427 -0.896248  1.118974 -0.969456   \n",
       "1 -0.887917  4.915272 -0.939446 -0.343677 -0.964685 -0.478649  4.342395   \n",
       "2 -0.923215  2.746968 -0.918085  0.047804 -0.908587 -0.451752  2.984481   \n",
       "3 -0.268866 -0.408416 -0.935145  0.731800 -0.922438  0.221781 -0.046606   \n",
       "4  0.529231 -0.829957 -0.897425  0.921280 -0.865304  0.331018 -0.644940   \n",
       "5 -0.793087  1.832985 -0.964968  0.274521 -0.962229 -0.288595  2.333454   \n",
       "6 -0.627914  0.537031 -0.846287  0.484149 -0.802970 -0.255616  1.103370   \n",
       "7 -0.825429  3.686025 -0.979020  0.053158 -0.983342 -0.448615  3.839871   \n",
       "8  1.978345 -0.941560 -0.906123  1.604776 -0.881297  0.819134 -0.879738   \n",
       "9  6.975595 -0.999944 -0.979416  5.483491 -0.976307  3.397312 -0.999714   \n",
       "\n",
       "     feat_8    feat_9   feat_10  ...   feat_24   feat_25   feat_26   feat_27  \\\n",
       "0  1.811707  2.560955  3.803463  ... -0.862891 -0.909545 -0.915361 -0.952061   \n",
       "1 -0.332870 -0.768041 -0.815375  ... -0.939201 -0.965917 -0.969461 -0.934799   \n",
       "2  0.535007 -0.591029 -0.324043  ... -0.809726 -0.929934 -0.891814 -0.881796   \n",
       "3  1.149634  0.592136  1.357959  ... -0.834968 -0.937475 -0.917737 -0.929519   \n",
       "4  1.296097  1.166863  2.036034  ... -0.775411 -0.881967 -0.864018 -0.908001   \n",
       "5  0.788157 -0.311396  0.353214  ... -0.923235 -0.969646 -0.970492 -0.961975   \n",
       "6  0.905729  0.121083  0.820827  ... -0.712115 -0.826480 -0.794454 -0.831328   \n",
       "7  0.161758 -0.641629 -0.414449  ... -0.970626 -0.987172 -0.992049 -0.977634   \n",
       "8  1.500830  1.694242  3.005683  ... -0.845833 -0.906470 -0.917842 -0.910915   \n",
       "9  2.934085  6.361970  9.293163  ... -0.980985 -0.976980 -0.982636 -0.989800   \n",
       "\n",
       "    feat_28   feat_29   feat_30   feat_31   feat_32  gt  \n",
       "0 -0.989461  1.911855  1.409705  2.303997 -0.981840  54  \n",
       "1  5.304822  0.934790 -0.410701  0.284690  4.919212  18  \n",
       "2  3.415373  1.044108 -0.442615  0.033648  2.628199  26  \n",
       "3 -0.226282  1.608048  0.276169  1.246468 -0.363367  33  \n",
       "4 -0.784495  1.329586  0.547925  1.195395 -0.810089  35  \n",
       "5  2.462071  1.539259 -0.132857  0.922628  2.249941  29  \n",
       "6  1.042797  0.713609 -0.003151  0.097357  0.469993  13  \n",
       "7  4.310089  1.683480 -0.217012  1.010501  4.100075  28  \n",
       "8 -0.926480  1.689097  1.170266  1.745933 -0.939529  43  \n",
       "9 -0.999934  5.141039  4.198592  6.156951 -0.999915  54  \n",
       "\n",
       "[10 rows x 33 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " - Total samples: 20475\n",
      " -  Feature of features (excluding target): 32\n"
     ]
    }
   ],
   "source": [
    "# Preview first entries \n",
    "print(\"First 10 entries in AGE_PREDICTION dataset:\")\n",
    "display(age_df.head(10))\n",
    "\n",
    "# Dataset shape\n",
    "print(f\"\\n - Total samples: {len(age_df)}\")\n",
    "print(f\" -  Feature of features (excluding target): {age_df.shape[1] - 1}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9065cf77",
   "metadata": {},
   "source": [
    "### **Age Distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dec29904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Improved histogram plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(age_df['gt'], bins=30, edgecolor='white', color='#4A90E2', alpha=0.85)\n",
    "plt.title(\"Age Distribution\", fontsize=16)\n",
    "plt.xlabel(\"Age\", fontsize=12)\n",
    "plt.ylabel(\"Frequency\", fontsize=12)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56dc18f",
   "metadata": {},
   "source": [
    "## **Part 1: Multi-Layer-Perceptron for age regression**\n",
    "------\n",
    "#### **Objective**\n",
    "In this part, we implement a **Multi-Layer Perceptron (MLP)** from scratch (no high-level DL frameworks) to solve a regression task: predict the age of a person based on features extracted from facial images.\n",
    "\n",
    "We aim to:\n",
    "\n",
    "-   Train a deep **MLP** with at least **2 hidden layers**\n",
    "\n",
    "-   Minimize **L2-regularized** squared loss\n",
    "\n",
    "-   Use `scipy.optimize` as optimizer (e.g., **L-BFGS-B**)\n",
    "\n",
    "-   Tune hyperparameters via **k-fold cross-validation**\n",
    "\n",
    "-   Evaluate performance using:\n",
    "\n",
    "    -   **MSE** (Mean Squared Error)\n",
    "\n",
    "    -   **MAPE** (Mean Absolute Percentage Error)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e113528",
   "metadata": {},
   "source": [
    "### **Theoretical Background**\n",
    "\n",
    "A Multi-Layer Perceptron is a feedforward neural network composed of layers of neurons. Each neuron performs a linear transformation followed by a non-linear activation. For this regression task, we define the loss function as:\n",
    "\n",
    "$$\n",
    "E(\\omega, \\beta) = \\frac{1}{N} \\sum_{i=1}^N (y_i - \\hat{y}_i)^2 + \\lambda \\sum_{l=1}^{L} \\|\\omega^{(l)}\\|_2^2\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $y_i$ is the true age\n",
    "- $\\hat{y}_i$ is the predicted age\n",
    "- $\\omega^{(l)}$ is the weight matrix for layer $l$\n",
    "- $\\lambda$ is the regularization coefficient\n",
    "\n",
    "The **regularization term** helps prevent overfitting by penalizing large weights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf0f6ee",
   "metadata": {},
   "source": [
    "### **Step 1: Data Preparation**  \n",
    "   We first separate features from the target, then apply **standardization**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b3a55e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ➤ Separate features and target\n",
    "X = age_df.drop(columns=['gt']).values     # Feature matrix\n",
    "y = age_df['gt'].values                    # Target vector "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1a3ecc",
   "metadata": {},
   "source": [
    "#### **Data Splitting and Normalization**\n",
    "\n",
    "We follow a **two-stage data strategy**:\n",
    "\n",
    "-   **Hold-out test set**: 20% of the dataset is reserved as an untouched test set for final evaluation.\n",
    "\n",
    "\n",
    "-   **Training/validation set**: The remaining 80% will be used for **k-fold cross-validation** to tune the model's hyperparameters.\n",
    "\n",
    "\n",
    "This separation ensures that the final test metrics are unbiased, as they reflect the model's generalization ability on unseen data after training and tuning.\n",
    "\n",
    "**Important**:  \n",
    "Feature standardization (`StandardScaler`) is applied only on the training set, using `fit_transform`.\n",
    "The test set is transformed using the same scaler via transform.\n",
    "\n",
    "This avoids **data leakage** — we must not use any information from the test set (like its **mean** or **standard deviation**) during training, as this would lead to overfitting and artificially low test error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c06fdc71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set samples: 16380\n",
      "Test set samples    : 4095\n"
     ]
    }
   ],
   "source": [
    "# ➤ Step 1: Split into training/validation and test set (80% / 20%)\n",
    "X_tr, X_ts, Y_tr, Y_ts = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "# ➤ Step 2: Standardize features using training set statistics only\n",
    "scaler = StandardScaler()\n",
    "X_tr = scaler.fit_transform(X_tr)   # Fit + transform on training set\n",
    "X_ts = scaler.transform(X_ts)       # Only transform test set\n",
    "\n",
    "# ➤ Dataset dimensions check\n",
    "print(f\"Training set samples: {X_tr.shape[0]}\")\n",
    "print(f\"Test set samples    : {X_ts.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cb5e35",
   "metadata": {},
   "source": [
    "### **Hyperparameter Tuning via Cross-Validation**\n",
    "\n",
    "To identify the best model architecture and regularization strength, we define a set of candidate configurations. Each configuration includes:\n",
    "\n",
    "* The number of hidden layers and neurons per layer\n",
    "* The non-linear activation function (`tanh` or `sigmoid`)\n",
    "* The L2 regularization coefficient λ\n",
    "\n",
    "These configurations will be evaluated via **5-fold cross-validation** using **Mean Absolute Percentage Error (MAPE)** as the metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6683594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ➤ Define model configurations\n",
    "input_dim = X_tr.shape[1]\n",
    "\n",
    "configs = [\n",
    "    {\"layers\": [input_dim, 32, 1],           \"activation\": \"tanh\",    \"lambda\": 1e-4},  # 1 hidden layer, light regularization\n",
    "    {\"layers\": [input_dim, 64, 32, 1],       \"activation\": \"tanh\",    \"lambda\": 1e-3},  # 2 hidden layers\n",
    "    {\"layers\": [input_dim, 64, 64, 32, 1],   \"activation\": \"sigmoid\", \"lambda\": 1e-4},  # 3 hidden layers, sigmoid\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4508c0",
   "metadata": {},
   "source": [
    "### **Performing 5-Fold Cross-Validation**\n",
    "\n",
    "We now evaluate each configuration using **5-fold cross-validation** on the training set:\n",
    "\n",
    "* Each fold is used once as validation, the remaining 4 for training.\n",
    "* The model is trained from scratch at each fold.\n",
    "* The average validation MAPE across the 5 folds is used to select the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80ab0710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " - Best Config Selected: {'layers': [32, 32, 1], 'activation': 'tanh', 'lambda': 0.0001}\n",
      "\n",
      "=== SELECTED CONFIGURATION ===\n",
      "Layers: [32, 32, 1]\n",
      "Activation: tanh\n",
      "Lambda: 0.0001\n",
      "Number of hidden layers: 1\n"
     ]
    }
   ],
   "source": [
    "best_config, all_results, best_score = cross_validate_model(\n",
    "    X_tr, Y_tr,\n",
    "    k_folds=5,\n",
    "    configs=configs,\n",
    "    scoring='mape'\n",
    ")\n",
    "\n",
    "# Display selected configuration\n",
    "print(\"\\n - Best Config Selected:\", best_config)\n",
    "\n",
    "print(\"\\n=== SELECTED CONFIGURATION ===\")\n",
    "print(f\"Layers: {best_config['layers']}\")\n",
    "print(f\"Activation: {best_config['activation']}\")\n",
    "print(f\"Lambda: {best_config['lambda']}\")\n",
    "print(f\"Number of hidden layers: {len(best_config['layers']) - 2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9edbef84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ALL CONFIGURATIONS ===\n",
      "{'layers': [32, 32, 1], 'activation': 'tanh', 'lambda': 0.0001} → Avg Val MAPE: 23.18\n",
      "{'layers': [32, 64, 32, 1], 'activation': 'tanh', 'lambda': 0.001} → Avg Val MAPE: 23.38\n",
      "{'layers': [32, 64, 64, 32, 1], 'activation': 'sigmoid', 'lambda': 0.0001} → Avg Val MAPE: 42.37\n"
     ]
    }
   ],
   "source": [
    "# Print results for all configurations\n",
    "print(\"\\n=== ALL CONFIGURATIONS ===\")\n",
    "for config, val_error in all_results:\n",
    "    print(f\"{config} → Avg Val MAPE: {val_error:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2be5c0",
   "metadata": {},
   "source": [
    "### **Final Model Training on Full Training Set**\n",
    "\n",
    "Once the best configuration is selected, we train the final model on the **entire training set**, using normalized targets.  \n",
    "The training is performed using the **L-BFGS-B optimizer** from `scipy.optimize`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44f9dfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize target for final training\n",
    "y_min, y_max = Y_tr.min(), Y_tr.max()\n",
    "Y_tr_norm = (Y_tr - y_min) / (y_max - y_min)\n",
    "\n",
    "# Train the final model\n",
    "final_model, opt_result, train_time = train_model(\n",
    "    X_tr, Y_tr_norm,\n",
    "    layer_sizes=best_config['layers'],\n",
    "    activation=best_config['activation'],\n",
    "    lambda_reg=best_config['lambda'],\n",
    "    max_iter=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3758af5b",
   "metadata": {},
   "source": [
    "### **Model Predictions and Denormalization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89afe306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on training and test set\n",
    "y_tr_pred = final_model.predict(X_tr) * (y_max - y_min) + y_min\n",
    "y_ts_pred = final_model.predict(X_ts) * (y_max - y_min) + y_min"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5198b4c",
   "metadata": {},
   "source": [
    "### **Model Evaluation**\n",
    "\n",
    "We now evaluate the model on both the training and test set using **MSE** and **MAPE**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a18802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- FINAL MODEL PERFORMANCE ---\n",
      "Training MSE  - LOSS: 94.6926\n",
      "Training MAPE : 23.09%\n",
      "Test MSE - LOSS     : 95.7274\n",
      "Test MAPE     : 23.68%\n"
     ]
    }
   ],
   "source": [
    "# Compute metrics\n",
    "mse_train = mean_squared_error(Y_tr, y_tr_pred)\n",
    "mape_train = mean_absolute_percentage_error(Y_tr, y_tr_pred) * 100\n",
    "\n",
    "mse_test = mean_squared_error(Y_ts, y_ts_pred)\n",
    "mape_test = mean_absolute_percentage_error(Y_ts, y_ts_pred) * 100\n",
    "\n",
    "# Display performance\n",
    "print(\"\\n--- FINAL MODEL PERFORMANCE ---\")\n",
    "print(f\"Training MSE - LOSS: {mse_train:.4f}\")\n",
    "print(f\"Training MAPE : {mape_train:.2f}%\")\n",
    "print(f\"Test MSE - LOSS     : {mse_test:.4f}\")\n",
    "print(f\"Test MAPE     : {mape_test:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc49cac2",
   "metadata": {},
   "source": [
    "### **Optimization Summary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a5f08a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== OPTIMIZATION DETAILS ===\n",
      "Optimizer success        : True\n",
      "Message                  : CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL\n",
      "Final loss (reg. error)  : 0.015254282174966678\n",
      "Number of iterations     : 579\n",
      "Optimization time        : 3.34 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== OPTIMIZATION DETAILS ===\")\n",
    "print(\"Optimizer success        :\", opt_result.success)\n",
    "print(\"Message                  :\", opt_result.message)\n",
    "print(\"Final loss (with regularization)  :\", opt_result.fun)\n",
    "print(\"Number of iterations     :\", opt_result.nit)\n",
    "print(f\"Optimization time        : {train_time:.2f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
